from pathlib import Path
import mne
from mne.minimum_norm import apply_inverse, make_inverse_operator
# from joblib import Parallel, delayed
import numpy as np
from scipy.io import savemat
# import matplotlib
# matplotlib.use('Agg')  # å¯é€‰ï¼šç¦æ­¢çª—å£å¼¹å‡º

import nibabel as nib
from collections import Counter

def check_thalamic_labels(mgz_path):
    """
    æ£€æŸ¥ ThalamicNuclei segmentation ä¸­çš„æ ‡ç­¾ ID ä»¥åŠå‡ºç°é¢‘æ¬¡ã€‚
    é€‚ç”¨äº FreeSurfer ç”Ÿæˆçš„ ThalamicNuclei.v13.T1.mgz
    """
    print(f"ğŸ§  è¯»å– MRI æ–‡ä»¶: {mgz_path}")
    img = nib.load(mgz_path)
    data = img.get_fdata()

    unique_vals, counts = np.unique(data, return_counts=True)
    label_counter = Counter(dict(zip(unique_vals.astype(int), counts)))

    print("ğŸ“Œ MRI ä¸­å‡ºç°çš„ label ID åŠå…¶ä½“ç´ æ•°é‡ï¼š")
    for label, count in label_counter.items():
        print(f"  Label ID {label}: {count} voxels")

    return label_counter



# input path
subjects_dir = Path("/Users/duyun530/PycharmProjects/mne/subjects")
subject = "sub101"

data_root = Path("/Users/duyun530/PycharmProjects/mne/data_pre_loc")
pre_loc_data_subject = "Sub101_Active"
session_root = data_root / pre_loc_data_subject

# output path
final_output_root = Path("/Users/duyun530/PycharmProjects/mne/final_output_All") / pre_loc_data_subject
final_output_root.mkdir(parents=True, exist_ok=True)

# parameter configure
fname_trans = str(subjects_dir / subject / f"{subject}-trans.fif")
fname_bem = str(subjects_dir / subject / f"{subject}-bem.fif")
fname_aseg = subjects_dir / subject / "mri"  / "ThalamicNuclei.v13.T1.mgz"
check_thalamic_labels(fname_aseg)

labels_vol = {"Left-VPL":8133}






def compute_forward(subject, subjects_dir, raw, fname_trans, fname_aseg, fname_bem):
    """æ„å»º surface + volume æºç©ºé—´å¹¶è¿”å› forward è§£å’Œ forward_src"""
    # è¯»å– BEM æ¨¡å‹
    bem = mne.read_bem_solution(fname_bem, verbose=False)

    # æ„å»ºçš®å±‚æºç©ºé—´ï¼ˆstandard surfaceï¼‰
    surface_src = mne.setup_source_space(
        subject, spacing="oct6", add_dist="patch",
        subjects_dir=subjects_dir, verbose=False
    )

    # åŠ å…¥ä½“ç§¯æºç©ºé—´ï¼ˆä¾‹å¦‚ä¸˜è„‘ï¼‰
    volume_src = mne.setup_volume_source_space(
        subject,
        mri=fname_aseg,
        bem=bem,
        volume_label=labels_vol,  # æˆ–å¤šä¸ª labelï¼Œä¾‹å¦‚ ["Left-VPL", "Right-VPL"]
        subjects_dir=subjects_dir,
        add_interpolator=True,
        verbose=False
        # n_jobs = 1,
    )

    # åˆå¹¶ surface + volume ä¸º forward_src
    forward_src = surface_src + volume_src

    # åˆ›å»º forward è§£
    fwd = mne.make_forward_solution(
        raw.info,
        trans=fname_trans,
        src=forward_src,
        bem=fname_bem,
        eeg=True,
        meg=False,
        mindist=5.0,
        verbose=False
        # n_jobs=1
    )
    print("ğŸ“Œ forward_src['src'] ç±»å‹:", type(forward_src))
    print("ğŸ“Œ forward_src['src'] å†…å®¹é¢„è§ˆ:", forward_src)
    return fwd, forward_src


def compute_inverse(evoked, fwd, noise_cov, snr=3.0, method='dSPM'):
    """è®¡ç®—é€‚ç”¨äº hybrid source space çš„é€†è§£"""

    # åˆ›å»º inverse operator
    inverse_operator = make_inverse_operator(
        evoked.info, fwd, noise_cov,
        depth=None,
        loose=dict(surface=0.2, volume=1.0),
        verbose=False
    )

    # åº”ç”¨ inverse è§£
    stc = apply_inverse(
        evoked, inverse_operator,
        lambda2=1.0 / snr ** 2,
        method=method,
        pick_ori=None,
        verbose=False
    )

    if stc is None:
        raise RuntimeError("âŒ apply_inverse() è¿”å› Noneï¼Œå¯èƒ½æ˜¯æ•°æ®ç»´åº¦ä¸åŒ¹é…æˆ–æ— æœ‰æ•ˆä¿¡å·")

    # è·å– inverse è§£ä½¿ç”¨çš„ source space
    inverse_src = inverse_operator['src']

    if inverse_operator is None or 'src' not in inverse_operator:
        raise RuntimeError("âŒ æ— æ³•ä» inverse_operator ä¸­æå– src")

    # âœ… å…³é”®æ£€æŸ¥
    if inverse_src is None:
        raise RuntimeError("âŒ inverse_operator['src'] æ˜¯ Noneï¼Œä¸èƒ½ç»§ç»­ï¼")
    if not isinstance(inverse_src, mne.SourceSpaces):
        raise TypeError(f"âŒ inverse_src ç±»å‹é”™è¯¯ï¼Œåº”ä¸º SourceSpacesï¼Œä½†å¾—åˆ° {type(inverse_src)}")

    print("ğŸ“Œ inverse_operator['src'] ç±»å‹:", type(inverse_src))
    print("ğŸ“Œ inverse_operator['src'] å†…å®¹é¢„è§ˆ:", inverse_src)


    return stc, inverse_src


def extract_left_vpl_timeseries_manual(stc, src, mode='voxel'):
    if src is None:
        raise RuntimeError("âŒ extract_features_dual æ”¶åˆ°çš„ src æ˜¯ Noneï¼")
    if not isinstance(src, mne.SourceSpaces):
        raise TypeError(f"âŒ extract_features_dual æ”¶åˆ°çš„ src ç±»å‹é”™è¯¯: {type(src)}")

    print("âœ… extract_features_dual() æ”¶åˆ°æœ‰æ•ˆçš„ src")

    print("ğŸ” å½“å‰ SourceSpaces åŒ…å«ä»¥ä¸‹ volume åŒºåŸŸï¼š")
    for i, s in enumerate(src):
        src_type = s['type']
        seg_name = s.get('seg_name', 'N/A')
        n_used = len(s['vertno'])
        print(f"  â–¶ Index {i}: type = {src_type}, seg_name = {seg_name}, n_used = {n_used}")

    # æŸ¥æ‰¾ volume source ç©ºé—´ä¸­ seg_name ä¸º Left-VPL çš„é‚£å—
    volume_src = [s for s in src if s['type'] == 'vol' and s.get('seg_name') == 'Left-VPL']
    if not volume_src:
        raise ValueError("âŒ æœªåœ¨ source space ä¸­æ‰¾åˆ° 'Left-VPL' volume label")

    vol = volume_src[0]
    vert_indices = vol['vertno']
    print(f"ğŸ” æ‰¾åˆ° 'Left-VPL' volume åŒºåŸŸï¼ŒåŒ…å« {len(vert_indices)} ä¸ªä½“ç´ ç‚¹")

    # MixedSourceEstimate çš„ data é¡ºåºæ˜¯ surface + volume
    n_surf = sum(len(s['vertno']) for s in src if s['type'] == 'surf')
    volume_data = stc.data[n_surf:, :]
    assert volume_data.shape[0] == len(vert_indices), "âŒ volume ç‚¹æ•°ä¸åŒ¹é…"

    if mode == 'voxel':
        return volume_data  # æ‰€æœ‰ä½“ç´ 
    elif mode == 'mean':
        return volume_data.mean(axis=0)  # å¹³å‡ä½“ç´ å€¼
    else:
        raise ValueError(f"âŒ ä¸æ”¯æŒçš„ mode: {mode}ï¼Œè¯·ä½¿ç”¨ 'mean' æˆ– 'voxel'")


def extract_features_dual(stc, src, evoked, raw, epochs, h_epochs, subject, subjects_dir):
    """
    ä» STC å’Œæ—¶åºæ•°æ®ä¸­æå–ä¸¤ä¸ªç‰ˆæœ¬ï¼š
    - æ··åˆç‰¹å¾ï¼šçš®å±‚ + Left-VPL
    - Left-VPL å•ç‹¬ç‰¹å¾
    """
    print("âœ… è¿›å…¥ extract_features_dual")
    print("ğŸ“Œ src ç±»å‹:", type(src))
    if src is None:
        raise RuntimeError("âŒ extract_features_dual æ”¶åˆ°çš„ src æ˜¯ Noneï¼")

    # === 1. æ£€æŸ¥ src å’Œ stc åŒ¹é… ===
    if isinstance(stc, mne.MixedSourceEstimate):
        n_src_pts = sum(len(s['vertno']) for s in src)
        print(f"ğŸ” STC ç‚¹æ•°: {stc.data.shape[0]}, SRC æ€»ç‚¹æ•°: {n_src_pts}")
        if stc.data.shape[0] != n_src_pts:
            raise ValueError(f"âŒ src ä¸ stc ä¸åŒ¹é…ï¼šsrc æ€»ç‚¹æ•° = {n_src_pts}ï¼Œä½† stc.shape[0] = {stc.data.shape[0]}")

    # === 2. è·å–çš®å±‚æ ‡ç­¾ ===
    labels_parc = mne.read_labels_from_annot(
        subject, parc='aparc', subjects_dir=subjects_dir, verbose=False
    )
    label_ts = mne.extract_label_time_course(
        [stc], labels_parc, src, mode="mean", allow_empty=True, verbose=False
    )
    label_ts_filtered = label_ts[0]
    label_names = [lbl.name for lbl in labels_parc]

    # === 3. Left-VPL æ ‡ç­¾æ—¶é—´åºåˆ— Mixed ===
    print("ğŸ§  å³å°†è°ƒç”¨ extract_left_vpl_timeseries")
    left_vpl_ts = extract_left_vpl_timeseries_manual(stc, src)
    print("âœ… extract_left_vpl_timeseries æˆåŠŸè¿”å›")

    # === âš ï¸ ä¿®æ­£ label_ts å’Œ label_names ä¸ä¸€è‡´é—®é¢˜ ===
    if label_ts_filtered.shape[0] != len(label_names):
        print(f"âš ï¸ label_ts è¡Œæ•°: {label_ts_filtered.shape[0]} ä¸ label_names æ•°é‡: {len(label_names)} ä¸ä¸€è‡´ï¼Œæ­£åœ¨ä¿®æ­£...")
        min_len = min(label_ts_filtered.shape[0], len(label_names))
        label_ts_filtered = label_ts_filtered[:min_len, :]
        label_names = label_names[:min_len]

    # mixed label = å¤§è„‘çš®å±‚ + Left-VPL
    label_ts_mixed = np.vstack([label_ts_filtered, left_vpl_ts])
    label_names_mixed = label_names + ["Left-VPL"]

    # === 4. ä»… Left-VPL ç‰¹å¾ ===
    label_ts_vpl = left_vpl_ts[None, :]  # shape: (1, n_times)
    label_names_vpl = ["Left-VPL"]

    # === 5. PSD ===
    def _compute_psd(data): return data.compute_psd(fmax=100, verbose=False).get_data(return_freqs=True)
    psd_raw, frq_raw = _compute_psd(raw)
    psd_epochs, frq_epochs = _compute_psd(epochs)
    psd_h, frq_h = _compute_psd(h_epochs)
    psd_evoked, frq_evoked = _compute_psd(evoked)

    common_psd = {
        'raw': (psd_raw, frq_raw),
        'epochs': (psd_epochs, frq_epochs),
        'h_epochs': (psd_h, frq_h),
        'evoked': (psd_evoked, frq_evoked),
    }

    features_mixed = {
        'label_ts': label_ts_mixed,
        'label_names': label_names_mixed,
        'times': 1e3 * stc.times,
        'psd': common_psd,
    }
    features_vpl = {
        'label_ts': label_ts_vpl,
        'label_names': label_names_vpl,
        'times': 1e3 * stc.times,
        'psd': common_psd,
    }

    return features_mixed, features_vpl

def save_features(features, output_path, meta=None):
    """
    ä¿å­˜ features ä¸º .npz å’Œ .mat æ–‡ä»¶ï¼Œæ–‡ä»¶åç”± output_path æŒ‡å®šï¼ˆä¸å«æ‰©å±•åï¼‰
    e.g. output_path = Path(".../mixed_features")
    """
    output_path.parent.mkdir(parents=True, exist_ok=True)

    save_data = {
        'label_ts': features['label_ts'],
        'label_names': features['label_names'],
        'times': features['times'],
    }

    for key, (psd, freqs) in features['psd'].items():
        save_data[f'psd_{key}'] = psd
        save_data[f'freqs_{key}'] = freqs

    if isinstance(meta, dict):
        for k, v in meta.items():
            save_data[f'meta_{k}'] = v

    # ä¿å­˜ .npz
    npz_path = output_path.with_suffix(".npz")
    np.savez(npz_path, **save_data)
    print(f"âœ… npzç‰¹å¾å·²ä¿å­˜è‡³: {npz_path}")

    # ä¿å­˜ .mat
    mat_path = output_path.with_suffix(".mat")
    mat_data = save_data.copy()
    mat_data['label_names'] = np.array(mat_data['label_names'], dtype=object)
    savemat(mat_path, mat_data)
    print(f"âœ… matç‰¹å¾å·²ä¿å­˜è‡³: {mat_path}")

    # âœ… é¢å¤–ä¿å­˜ä¸€ä¸ª summary.csv ç»Ÿè®¡æ–‡ä»¶ï¼ˆå¹³å‡æ¿€æ´»å€¼ per labelï¼‰
    # import pandas as pd
    # label_names = list(features['label_names'])
    # mean_activation = features['label_ts'].mean(axis=1)
    # print("label_ts shape:", features['label_ts'].shape)
    # print("label_names æ•°é‡:", len(features['label_names']))
    #
    # if len(label_names) != len(mean_activation):
    #     raise ValueError("label_names ä¸ mean_activation é•¿åº¦ä¸ä¸€è‡´")
    #
    # summary_data = {
    #     'label': label_names,
    #     'mean_activation': mean_activation
    # }
    # for key in ['session', 'subject', 'type']:
    #     meta_key = f'meta_{key}'
    #     if meta_key in save_data:
    #         summary_data[key] = [save_data[meta_key]] * len(label_names)
    #
    # df_summary = pd.DataFrame(summary_data)
    # csv_path = output_path.with_suffix(".summary.csv")
    # df_summary.to_csv(csv_path, index=False)
    # print(f"ğŸ“„ summary.csv å·²ä¿å­˜è‡³: {csv_path}")


# ====== main ======
for session_dir in session_root.iterdir():
    if not session_dir.is_dir():
        continue

    print(f"\nğŸ” å¤„ç† session: {session_dir.name}")

    # try:
    raw_path = session_dir / "raw_with_stim.fif"
    evoked_path = session_dir / "evoked_ave.fif"
    cov_path = session_dir / "noise_cov.fif"
    epochs_path = session_dir / "epochs_epo.fif"

    # === 1. è¯»å–æ•°æ® ===
    raw = mne.io.read_raw_fif(raw_path, preload=True)
    raw.set_eeg_reference(projection=True)

    evoked = mne.read_evokeds(evoked_path, condition=0, baseline=(None, 0))
    evoked.set_eeg_reference(projection=True)
    evoked.apply_proj()

    cov = mne.read_cov(cov_path)
    epochs = mne.read_epochs(epochs_path, preload=True)
    epochs.set_eeg_reference(projection=True)
    epochs.apply_proj()  # âœ… æ¨èä¹ŸåŠ ä¸Šï¼Œä¿æŒä¸€è‡´æ€§
    h_epochs = epochs["HandStim"] if "HandStim" in epochs.event_id else epochs

    # === 2. ä½¿ç”¨ä½ çš„å‡½æ•°æ„å»º forward è§£ï¼ˆåŒ…å« MRIï¼‰===
    fwd, forward_src = compute_forward(
        subject=subject,
        subjects_dir=str(subjects_dir),
        raw=raw,
        fname_trans=str(fname_trans),
        fname_aseg=str(fname_aseg),
        fname_bem=str(fname_bem)
    )
    print("âœ… Forward è§£ï¼ˆå« MRIï¼‰å·²å®Œæˆ")

    # === 3. åˆ›å»º inverse operator å¹¶è®¡ç®—æºå®šä½ ===
    stc, inverse_src_= compute_inverse(
        evoked=evoked,
        fwd=fwd,
        noise_cov=cov,
        snr=3.0,
        method='dSPM'
    )
    # âœ… æ‰“å°è°ƒè¯•ä¿¡æ¯
    print("âœ… Inverse è§£å®Œæˆ")

    print("ğŸ“Œ inverse_src ç±»å‹:", type(inverse_src_))
    print("ğŸ“Œ inverse_src æ˜¯å¦ None:", inverse_src_ is None)
    print("ğŸ“Œ stc ç±»å‹:", type(stc))
    print("ğŸ“Œ stc shape:", stc.data.shape)

    if inverse_src_ is None:
        raise RuntimeError("âŒ inverse_src æ˜¯ Noneï¼Œæ— æ³•ç”¨äº extract_featuresã€‚")
    if not isinstance(inverse_src_, mne.SourceSpaces):
        raise TypeError(f"âŒ inverse_src ç±»å‹é”™è¯¯ï¼Œåº”ä¸º SourceSpacesï¼Œä½†å¾—åˆ° {type(inverse_src_)}")

    print("ğŸš¨ è°ƒç”¨ extract_features_dual å‰ inverse_src ç±»å‹:", type(inverse_src_))
    assert inverse_src_ is not None, "âŒ inverse_src æ˜¯ Noneï¼Œä¸èƒ½ä¼ ç»™ extract_features_dual"

    # === 4. è®¾ç½®æ¯ä¸ª session çš„è¾“å‡ºç›®å½• ===
    session_output = final_output_root / session_dir.name
    session_output.mkdir(parents=True, exist_ok=True)

    # === 5. stc file ===
    stc_path = session_output / "stc"
    stc.save(str(stc_path), overwrite=True)

    # === 6. stc png ===
    try:
        brain = stc.plot(subject=subject, subjects_dir=str(subjects_dir),
                         initial_time=stc.get_peak()[1], time_unit="s",
                         size=(800, 600),surface='pial',src=inverse_src_)
        fig_path = session_output / "stc.png"
        brain.save_image(str(fig_path))
        brain.close()
    except Exception as e:
        print(f"âš ï¸ stc å¯è§†åŒ–å¤±è´¥: {e}")



    # === 7.save mat & npz ===

    print("ğŸš¨ è°ƒç”¨ extract_features_dual å‰ inverse_src ç±»å‹:", type(inverse_src_))
    # features_mixed, features_vpl = extract_features_dual(
    #     stc=stc, src=inverse_src_, evoked=evoked, raw=raw,
    #     epochs=epochs, h_epochs=h_epochs,
    #     subject=subject, subjects_dir=subjects_dir
    # )
    #
    # save_features(
    #     features_mixed,
    #     session_output / "mixed_features",
    #     meta={
    #         'type': 'mixed',
    #         'subject': subject,
    #         'session': session_dir.name
    #     }
    # )

    # save_features(
    #     features_vpl,
    #     session_output / "left_vpl_features",
    #     meta={
    #         'type': 'left_vpl_only',
    #         'subject': subject,
    #         'session': session_dir.name
    #     }
    # )
    # print("âœ… left_vpl_onlyç‰¹å¾ä¿å­˜å®Œæˆ")

    # === ğŸ” ä¿å­˜ Left-VPL æ‰€æœ‰ä½“ç´ çš„æ—¶åºæ•°æ®ï¼ˆvoxel-wiseï¼‰ ===
    print("ğŸ’¾ æ­£åœ¨æå–å¹¶ä¿å­˜ Left-VPL voxel-wise æ—¶åºæ•°æ®...")
    left_vpl_voxel_ts = extract_left_vpl_timeseries_manual(stc, inverse_src_,
                                                           mode='voxel')  # shape: (n_voxels, n_times)
    print(f"ğŸ“ left_vpl_voxel_ts shape: {left_vpl_voxel_ts.shape}")
    voxel_ts_output_path = session_output / "left_vpl_voxels.mat"
    savemat(str(voxel_ts_output_path), {
        'left_vpl_voxel_ts': left_vpl_voxel_ts,
        'times': 1e3 * stc.times  # æ¯«ç§’å•ä½
    })
    print(f"âœ… voxel-wise æ—¶åºæ•°æ®å·²ä¿å­˜è‡³: {voxel_ts_output_path}")

    # except Exception as e:
    #     print(f"âŒ é”™è¯¯å¤„ç† session {session_dir.name}: {e}")











